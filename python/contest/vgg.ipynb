{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_files( file_dir ):\n",
    "    aluminum = []\n",
    "    label = []\n",
    "    for i in range( 12 ):\n",
    "        for file in os.listdir( file_dir + '/' + str( i ) ):\n",
    "            if not file.endswith('.jpg') or file.startswith('.'):\n",
    "                continue  # Skip!\n",
    "            aluminum.append( file_dir + '/' + str( i ) + '/' + file )\n",
    "            label.append( i )\n",
    "    temp = np.array([ aluminum, label ])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle( temp )\n",
    "\n",
    "    aluminum_list = list( temp[:, 0] )\n",
    "    label_list = list( temp[:, 1] )\n",
    "    label_list_temp = [int(i) for i in label_list]\n",
    "    label_list = np.zeros( [len( label_list_temp ), 12] )\n",
    "    for i in range( len(label_list_temp ) ):\n",
    "        label_list[i][label_list_temp[i]] = 1\n",
    "    \n",
    "    return aluminum_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch( image, label, image_width, image_height, batch_size, capacity):\n",
    "    image = tf.cast( image, tf.string )\n",
    "    label = tf.cast( label, tf.float32 )\n",
    "    \n",
    "    input_queue = tf.train.slice_input_producer( [image, label] )\n",
    "    \n",
    "    label = input_queue[1]\n",
    "    image_contents = tf.read_file( input_queue[0] )\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=3) \n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, image_width\n",
    "                                                   , image_height)\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    image_batch, label_batch = tf.train.batch( [image, label],\n",
    "                                                                 batch_size = batch_size,\n",
    "                                                                  num_threads = 1, \n",
    "                                                                 capacity = capacity )\n",
    "    label_batch = tf.reshape(  label_batch, [batch_size, 12] )\n",
    "    \n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "CAPACITY = 2100\n",
    "IMG_W = 384\n",
    "IMG_H = 384\n",
    "\n",
    "train_dir = 'guangdong_round1_train2_20180916'\n",
    "image_list, label_list = get_files( train_dir )\n",
    "image_batch, label_batch = get_batch( image_list, label_list, IMG_W, IMG_H, BATCH_SIZE, CAPACITY )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_op( input_op, name, kh, kw, n_out, dh, dw, p ):\n",
    "    n_in = input_op.get_shape()[-1].value\n",
    "\n",
    "    with tf.name_scope( name ) as scope:\n",
    "        kernel = tf.get_variable( scope + \"w\",\n",
    "            shape = [kh, kw, n_in, n_out], dtype = tf.float32,\n",
    "            initializer = tf.contrib.layers.xavier_initializer_conv2d() )   \n",
    "            #Xavier in chapter 4\n",
    "\n",
    "        conv = tf.nn.conv2d( input_op, kernel, (1, dh, dw, 1), \n",
    "                        padding = 'SAME' )\n",
    "        bias_init_val = tf.constant( 0.0, shape = [n_out], \n",
    "                                    dtype = tf.float32 )\n",
    "        biases = tf.Variable( bias_init_val, trainable = True, name = 'b' )\n",
    "        z = tf.nn.bias_add( conv, biases )\n",
    "        activation = tf.nn.relu( z, name = scope )\n",
    "        p += [kernel, biases]\n",
    "        return activation\n",
    "\n",
    "def fc_op( input_op, name, n_out, p ):\n",
    "    n_in = input_op.get_shape()[-1].value\n",
    "\n",
    "    with tf.name_scope( name ) as scope:\n",
    "        kernel = tf.get_variable( scope + \"w\", \n",
    "            shape = [n_in, n_out], dtype = tf.float32,\n",
    "            initializer = tf.contrib.layers.xavier_initializer() )\n",
    "        biases = tf.Variable( tf.constant( 0.1, shape = [n_out],\n",
    "                                        dtype = tf.float32), name = 'b' )\n",
    "        activation = tf.nn.relu_layer( input_op, kernel, biases, \n",
    "                                    name = scope )\n",
    "        p += [kernel, biases]\n",
    "        return activation\n",
    "\n",
    "def mpool_op( input_op, name, kh, kw, dh, dw ):\n",
    "    return tf.nn.max_pool( input_op, ksize = [1, kh, kw, 1],\n",
    "                                     strides = [1, kh, kw, 1],\n",
    "                                     padding = 'SAME',\n",
    "                                     name = name )\n",
    "\n",
    "def inference_op( input_op, keep_prob ):\n",
    "    p = []\n",
    "    \n",
    "    #convolution1:\n",
    "    conv1_1 = conv_op( input_op, name = \"conv1_1\", kh = 3, kw = 3,\n",
    "                        n_out = 64, dh = 1, dw = 1, p = p )\n",
    "    conv1_2 = conv_op( conv1_1, name = \"conv1_2\", kh = 3, kw = 3,\n",
    "                        n_out = 64, dh = 1, dw = 1, p = p )\n",
    "    pool1 = mpool_op( conv1_2, name = \"pool1\", kh = 2, kw = 2,\n",
    "                        dh = 2, dw = 2 )\n",
    "\n",
    "    #convolution2:\n",
    "    conv2_1 = conv_op( pool1, name = \"conv2_1\", kh = 3, kw = 3,\n",
    "                        n_out = 128, dh = 1, dw = 1, p = p )\n",
    "    conv2_2 = conv_op( conv2_1, name = \"conv2_2\", kh = 3, kw = 3,\n",
    "                        n_out = 128, dh = 1, dw = 1, p = p )\n",
    "    pool2 = mpool_op( conv2_2, name = \"pool2\", kh = 2, kw = 2,\n",
    "                        dh = 2, dw = 2 )\n",
    "\n",
    "    #convolution3\n",
    "    conv3_1 = conv_op( pool2, name = \"conv3_1\", kh = 3, kw = 3,\n",
    "                        n_out = 256, dh = 1, dw = 1, p = p )\n",
    "    conv3_2 = conv_op( conv3_1, name = \"conv3_2\", kh = 3, kw = 3,\n",
    "                        n_out = 256, dh = 1, dw = 1, p = p )\n",
    "    conv3_3 = conv_op( conv3_2, name = \"conv3_3\", kh = 3, kw = 3,\n",
    "                        n_out = 256, dh = 1, dw = 1, p = p )\n",
    "    pool3 = mpool_op( conv3_3, name = \"pool3\", kh = 2, kw = 2,\n",
    "                        dh = 2, dw = 2 )\n",
    "    \n",
    "    #convolution4\n",
    "    conv4_1 = conv_op( pool3, name = \"conv4_1\", kh = 3, kw = 3,\n",
    "                        n_out = 512, dh = 1, dw = 1, p = p )\n",
    "    conv4_2 = conv_op( conv4_1, name = \"conv4_2\", kh = 3, kw = 3,\n",
    "                        n_out = 512, dh = 1, dw = 1, p = p )\n",
    "    conv4_3 = conv_op( conv4_2, name = \"conv4_3\", kh = 3, kw = 3,\n",
    "                        n_out = 512, dh = 1, dw = 1, p = p )\n",
    "    pool4 = mpool_op( conv4_3, name = \"pool4\", kh = 2, kw = 2,\n",
    "                        dh = 2, dw = 2 )\n",
    "\n",
    "    #convolution5\n",
    "    conv5_1 = conv_op( pool4, name = \"conv5_1\", kh = 3, kw = 3,\n",
    "                        n_out = 512, dh = 1, dw = 1, p = p )\n",
    "    conv5_2 = conv_op( conv5_1, name = \"conv5_2\", kh = 3, kw = 3,\n",
    "                        n_out = 512, dh = 1, dw = 1, p = p )\n",
    "    conv5_3 = conv_op( conv5_2, name = \"conv5_3\", kh = 3, kw = 3,\n",
    "                        n_out = 512, dh = 1, dw = 1, p = p )\n",
    "    pool5 = mpool_op( conv5_3, name = \"pool5\", kh = 2, kw = 2,\n",
    "                        dh = 2, dw = 2 )\n",
    "    \n",
    "    #reshape\n",
    "    shp = pool5.get_shape()\n",
    "    flattened_shape = shp[1].value * shp[2].value * shp[3].value\n",
    "    resh1 = tf.reshape( pool5, [-1, flattened_shape], name = \"resh1\" )\n",
    "\n",
    "    #full connection6\n",
    "    fc6 = fc_op( resh1, name = \"fc6\", n_out = 1024, p = p )\n",
    "    fc6_drop = tf.nn.dropout( fc6, keep_prob, name = \"fc6_drop\" )\n",
    "\n",
    "    #full conneciton7\n",
    "    fc7 = fc_op( fc6_drop, name = \"fc7\", n_out = 1024, p = p )\n",
    "    fc7_drop = tf.nn.dropout( fc7, keep_prob, name = \"fc7_drop\" )\n",
    "    \n",
    "    fc8 = fc_op( fc7_drop, name = \"fc8\", n_out = 12, p = p )\n",
    "    softmax = tf.nn.softmax( fc8, name = \"softmax\" )\n",
    "    predictions = tf.argmax( softmax, 1, name = \"predictions\" )\n",
    "    return predictions, softmax, fc8, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder( tf.float32, [None, IMG_W, IMG_H, 3], name = \"x\" )\n",
    "y_ = tf.placeholder( tf.float32, [None, 12], name = \"y_\")\n",
    "keep_prob = tf.placeholder( tf.float32, name = \"keep_prob\" )\n",
    "learning_rate = tf.placeholder( tf.float32, name = \"learning_rate\" )\n",
    "\n",
    "predictions, softmax, fc8, p = inference_op( x, keep_prob )\n",
    "cross_entropy = tf.reduce_mean( -tf.reduce_sum( y_ * tf.log(softmax), reduction_indices = [1] ) )\n",
    "train_step = tf.train.AdamOptimizer( learning_rate ).minimize( cross_entropy )\n",
    "correct_prediction = tf.equal( predictions, tf.argmax( y_, 1 ) )\n",
    "\n",
    "accuracy = tf.reduce_mean( tf.cast( correct_prediction, tf.float32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    i = 0\n",
    "\n",
    "    sess.run( tf.global_variables_initializer() )\n",
    "    sess.run( tf.local_variables_initializer() )\n",
    "\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners( coord=coord )\n",
    "\n",
    "    try:\n",
    "        while not coord.should_stop() and i <= 10000:\n",
    "            img, label = sess.run( [image_batch, label_batch] )\n",
    "\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                train_accuracy = accuracy.eval( feed_dict = \n",
    "                                               {x: img, y_: label, keep_prob: 1.0} )\n",
    "                print( \"step %d, training accuracy %g\"%( i, train_accuracy ) )\n",
    "            \n",
    "            if i % 1000 == 0:\n",
    "                saver.save(sess, 'model/')\n",
    "            train_step.run( feed_dict = {x: img, y_: label, keep_prob: 0.5, learning_rate: 1e-4} )\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('done!')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
